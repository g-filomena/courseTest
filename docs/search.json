[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Web Mapping and Geovisualisation",
    "section": "",
    "text": "Welcome\nThis is the website for “Web Mapping and Geovisualisation” (module ENVS456) at the University of Liverpool. This course is designed and delivered by Dr. Gabriele Filomena and Dr. Elisabetta Pietrostefani from the Geographic Data Science Lab at the University of Liverpool, United Kingdom. The module has two main aims. It seeks to provide hands-on experience and training in:\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International. A compilation of this web course is hosted as a GitHub repository that you can access:",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Web Mapping and Geovisualisation",
    "section": "Contact",
    "text": "Contact\n\nGabriele Filomena - gfilo [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 1xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.\n\n\nElisabetta Pietrostefani - e.pietrostefani [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 6xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "general/overview.html",
    "href": "general/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Aims\nThis module aims to provide hands-on experience and training in: - The design and generation of (good looking) web-based mapping and geographical information tools. - The use of software to access, analyse and visualize web-based geographical information.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "general/overview.html#learning-outcomes",
    "href": "general/overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the module, students should be able to:\n\nVisualise and represent geo-data through static and dynamic maps.\nRecognise and describe the component of web based mapping infrastructure.\nCollect Web-based data.\nGenerate interactive maps and dashboards.\nUnderstand basic concepts of spatial network analysis.\nManipulate geo-data through scripting in Python.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "general/overview.html#feedback",
    "href": "general/overview.html#feedback",
    "title": "Overview",
    "section": "Feedback",
    "text": "Feedback\nFormal assessment. Two pieces of coursework (50%/50%). Equivalent to 2,500 words each\nVerbal face-to-face feedback. Immediate face-to-face feedback will be provided during computer, discussion and clinic sessions in interaction with staff. This will take place in all live sessions during the semester. Teams Forum. Asynchronous written feedback will be provided via Teams. Students are encouraged to contribute by asking and answering questions relating to the module content. Staff will monitor the forum Monday to Friday 9am-5pm, but it will be open to students to make contributions at all times. Response time will vary depending on the complexity of the question and staff availability.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "labs/w01_intro.html",
    "href": "labs/w01_intro.html",
    "title": "1  Introduction & Python Refresher",
    "section": "",
    "text": "1.1 Part I: Powerful Web Mapping Examples\nThis part of the lab has two main components: 1. The first one will require you to find a partner and work together with her/him 2. And the second one will involve group discussion.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-i-powerful-web-mapping-examples",
    "href": "labs/w01_intro.html#part-i-powerful-web-mapping-examples",
    "title": "1  Introduction & Python Refresher",
    "section": "",
    "text": "1.1.1 Paired Activity\nIn pairs, find three examples where web maps are used to communicate an idea. Complete the following sheet for each example:\n\nSubstantive\n\nTitle: Title of the map/project\nAuthor: Who is behind the project?\nBig idea: a “one-liner” on what the project tries to accomplish –\nMessage: what does the map try to get accross\n\nTechnical\n\nURL:\nInteractivity: does the map let you interact with it in any way? Yes/No\nZoomable: can you explore the map at different scales? Yes/No\nTooltips:\nBasemap: Is there an underlying map providing geographical context? Yes/No. If so, who is it provided by?\nTechnology: can you guess what technology does this map rely on?\n\n\nPost each sheet as a separate item on the Teams channel for Lab No.1\n\n1.1.1.1 Example\nThe project “WHO Coronavirus (COVID-19) Dashboard”\n\n\nSubstantive\n\nTitle: WHO Coronavirus (COVID-19) Dashboard\nAuthor: World Health Organization\nBig idea: Shows confirmed COVID-19 cases and deaths by country to date\nMessage: The project displays a map of the world where COVID-19 cases are shown by country. This element is used to show which countries have had more cases (large trends). A drop down button allows us to visualise the map by a) Total per 100,000 population b) % change in the last 7 days c) newly reported in the last 7 days d) newly reported in the last 24 hours.\n\nTechnical\n\nURL: https://covid19.who.int/\nInteractivity: Yes\nZoomable: Yes\nTooltips: Yes\nBasemap: No\nTechnology: Unknown\n\n\nHere are a couple of other COVID-19 examples of web-maps that where basemaps and technology is easier to spot.\n\n“London School of Hygiene & Tropical Medicine - COVID-19 tracker”\n“Tracking Coronavirus in the United Kingdom: Latest Map and Case Count”\n\n\n\n\n1.1.2 Class discussion\nWe will select a few examples posted and collectively discuss (some of) the following questions:\n\nWhat makes them powerful, what “speaks” to us?\nWhat could be improved, what is counter-intuitive?\nWhat design elements do they rely on?\nWhat technology do they use?\n\n\n\n1.1.3 References\n\nFor an excellent coverage of “visualisation literacy”, Chapter 11 of Andy Kirk’s “Data Visualisation” is a great start. Lab: Getting up to speed for web mapping\nA comprehensive overview of computational notebooks and how they relate to modern scientific work is available on Ch.1 of the GDS book.\nA recent overview of notebooks in Geography is available in Boeing & Arribas-Bel (2021)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-ii-pythonpandas-refresher",
    "href": "labs/w01_intro.html#part-ii-pythonpandas-refresher",
    "title": "1  Introduction & Python Refresher",
    "section": "1.2 Part II: Python/Pandas (Refresher)",
    "text": "1.2 Part II: Python/Pandas (Refresher)\nGabriele Filomena has prepared this notebook by readapting material shared on this repository. Copyright (c) 2013-2023 Geoff Boeing.\n\n1.2.1 Python\nA quick overview of ubiquitous programming concepts including data types, for loops, if-then-else conditionals, and functions.\n\nimport numpy as np\nimport pandas as pd\n\n\n# integers (int)\nx = 100\ntype(x)\n\n\n# floating-point numbers (float)\nx = 100.5\ntype(x)\n\n\n# sequence of characters (str)\nx = 'Los Angeles, CA 90089'\nlen(x)\n\n\n# list of items\nx = [1, 2, 3, 'USC']\nlen(x)\n\n\n# sets are unique\nx = {2, 2, 3, 3, 1}\nx\n\n\n# tuples are immutable sequences\nlatlng = (34.019425, -118.283413)\ntype(latlng)\n\n\n# you can unpack a tuple\nlat, lng = latlng\ntype(lat)\n\n\n# dictionary of key:value pairs\niceland = {'Country': 'Iceland', 'Population': 372520, 'Capital': 'Reykjavík', '% Foreign Population' : 0.18 }\ntype(iceland)\n\n\n# you can convert types\nx = '100'\nprint(type(x))\ny = int(x)\nprint(type(y))\n\n\n# you can loop through an iterable, such as a list or tuple\nfor coord in latlng:\n    print('Current coordinate is:', coord)\n\n\n# loop through a dictionary keys and values as tuples\nfor key, value in iceland.items():\n    print(key, value)\n\n\n# booleans are trues/falses\nx = 101\nx &gt; 100\n\n\n# use two == for equality and one = for assignment\nx == 100\n\n\n# if, elif, else for conditional branching execution\nx = 101\nif x &gt; 100:\n    print('Value is greater than 100.')\nelif x &lt; 100:\n    print('Value is less than 100.')\nelse:\n    print('Value is 100.')\n\n\n# use functions to encapsulate and reuse bits of code\ndef convert_items(my_list, new_type=str):\n    # convert each item in a list to a new type\n    new_list = [new_type(item) for item in my_list]\n    return new_list\n\nl = [1, 2, 3, 4]\nconvert_items(l)\n\n\n\n1.2.2 pandas Series and DataFrames\npandas has two primary data structures we will work with: Series and DataFrame.\n\n1.2.2.1 Pandas Series\n\n# a pandas series is based on a numpy array: it's fast, compact, and has more functionality\n# it has an index which allows you to work naturally with tabular data\nmy_list = [8, 5, 77, 2]\nmy_series = pd.Series(my_list)\nmy_series\n\n\n# look at a list-representation of the index\nmy_series.index.tolist()\n\n\n# look at the series' values themselves\nmy_series.values\n\n\n# what's the data type of the series' values?\ntype(my_series.values)\n\n\n# what's the data type of the individual values themselves?\nmy_series.dtype\n\n\n\n1.2.2.2 Pandas DataFrames\n\n# a dict can contain multiple lists and label them\nmy_dict = {'hh_income'  : [75125, 22075, 31950, 115400],\n           'home_value' : [525000, 275000, 395000, 985000]}\nmy_dict\n\n\n# a pandas dataframe can contain one or more columns\n# each column is a pandas series\n# each row is a pandas series\n# you can create a dataframe by passing in a list, array, series, or dict\ndf = pd.DataFrame(my_dict)\ndf\n\n\n# the row labels in the index are accessed by the .index attribute of the DataFrame object\ndf.index.tolist()\n\n\n# the column labels are accessed by the .columns attribute of the DataFrame object\ndf.columns\n\n\n# the data values are accessed by the .values attribute of the DataFrame object\n# this is a numpy (two-dimensional) array\ndf.values\n\n\n\n\n1.2.3 Loading data in Pandas\nUsually, you’ll work with data by loading a dataset file into pandas. CSV is the most common format. But pandas can also ingest tab-separated data, JSON, and proprietary file formats like Excel .xlsx files, Stata, SAS, and SPSS.\nBelow, notice what pandas’s read_csv function does:\n\nRecognize the header row and get its variable names.\nRead all the rows and construct a pandas DataFrame (an assembly of pandas Series rows and columns).\nConstruct a unique index, beginning with zero.\nInfer the data type of each variable (i.e., column).\n\n\n# load a data file\n# note the relative filepath! where is this file located?\n# use dtype argument if you don't want pandas to guess your data types\ndf = pd.read_csv('../data/GTD_2022.csv', low_memory = False)\n\n\nto_replace = [-9, -99, \"-9\", \"-99\"]\nfor value in to_replace:\n    df = df.replace(value, np.NaN)\n\ndf['eventid'] = df['eventid'].astype(\"Int64\")\n\n\n# dataframe shape as rows, columns\ndf.shape\n\n\n# or use len to just see the number of rows\nlen(df)\n\n\n# view the dataframe's \"head\"\ndf.head()\n\n\n# view the dataframe's \"tail\"\ndf.tail()\n\n\n# column data types\ndf.dtypes\n\n\n# or\nfor dt in df.columns[:10]:\n    print(dt, type(dt))\n\n\n\n1.2.4 Selecting and slicing data from a DataFrame\n\n# CHEAT SHEET OF COMMON TASKS\n# Operation                       Syntax           Result\n#------------------------------------------------------------\n# Select column by name           df[col]          Series\n# Select columns by name          df[col_list]     DataFrame\n# Select row by label             df.loc[label]    Series\n# Select row by integer location  df.iloc[loc]     Series\n# Slice rows by label             df.loc[a:c]      DataFrame\n# Select rows by boolean vector   df[mask]         DataFrame\n\n\n1.2.4.1 Select DataFrame’s column(s) by name\n\n# select a single column by column name\n# this is a pandas series\ndf['country']\n\n\n# select multiple columns by a list of column names\n# this is a pandas dataframe that is a subset of the original\ndf[['country_txt', 'year']]\n\n\n# create a new column by assigning df['new_col'] to some values\n# people killed every perpetrator \ndf['killed_per_attacker'] = df['nkill'] / df['nperps']\n\n# inspect the results\ndf[['country', 'year', 'nkill', 'nperps', 'killed_per_attacker']].head(15)\n\n\n\n1.2.4.2 Select row(s) by label\n\n# use .loc to select by row label\n# returns the row as a series whose index is the dataframe column names\ndf.loc[0]\n\n\n# use .loc to select single value by row label, column name\ndf.loc[15, 'gname'] #group name\n\n\n# slice of rows from label 5 to label 7, inclusive\n# this returns a pandas dataframe\ndf.loc[5:7]\n\n\n# slice of rows from label 17 to label 27, inclusive\n# slice of columns from country_txt to city, inclusive\ndf.loc[17:27, 'country_txt':'city']\n\n\n# subset of rows from with labels in list\n# subset of columns with names in list\ndf.loc[[1, 350], ['country', 'gname']]\n\n\n# you can use a column of identifiers as the index (indices do not *need* to be unique)\ndf_gname = df.set_index('gname')\ndf_gname.index.is_unique\n\n\ndf_gname.head(3)\n\n\n# .loc works by label, not by position in the dataframe\ntry:\n    df_gname.loc[0]\nexcept KeyError as e:\n    print('label not found')\n\n\n# the index now contains gname values, so you have to use .loc accordingly to select by row label\ndf_gname.loc['Taliban'].head()\n\n\n\n1.2.4.3 Select by (integer) position - Independent from actual Index\n\n# get the row in the zero-th position in the dataframe\ndf.iloc[0]\n\n\n# you can slice as well\n# note, while .loc is inclusive, .iloc is not\n# get the rows from position 0 up to but not including position 3 (ie, rows 0, 1, and 2)\ndf.iloc[0:3]\n\n\n# get the value from the row in position 3 and the column in position 2 (zero-indexed)\ndf.iloc[3, 6] #country_txt\n\n\n\n1.2.4.4 Select/filter by value\nYou can subset or filter a dataframe for based on the values in its rows/columns.\n\n# filter the dataframe by urban areas with more than 25 million residents\ndf[df['nkill'] &gt; 30].head()\n\n\n# you can chain multiple conditions together\n# pandas logical operators are: | for or, & for and, ~ for not\n# these must be grouped by using parentheses due to order of operations\ndf[['country','nkill', 'nwound']][(df['nkill'] &gt; 200) & (df['nwound'] &gt; 10)].head()\n# columns on the left-hand side are here used to slice the resulting output\n\n\n# ~ means not... it essentially flips trues to falses and vice-versa\ndf[['country','nkill', 'nwound']][~(df['nkill'] &gt; 200) & (df['nwound'] &gt; 10)]\n\n\n\n\n1.2.5 Grouping and summarizing\n\n# group by terroristic group name\ngroups = df.groupby('gname')\n\n\n# what is the median number of people killed per event across the different groups?\ngroups['nkill'].median().sort_values(ascending=False)\n\n\n# look at several columns' medians by group\ngroups[['nkill', 'nwound', 'nperps']].median()\n\n\n# you can create a new dataFrame by directly passing columns between \"[[ ]]\", after the groupby function\n# to do so, you also need to pass a function that can deal with the values (e.g. sum..etc) \nwestern_europe = df[df.region_txt == 'Western Europe']\nwestern_europe.groupby('country_txt')[['nkill', 'nwound']].sum().sort_values('nkill', ascending = False).reset_index()\n\n\n\n1.2.6 Indexes\nEach DataFrame has an index. Indexes do not have to be unique (but that would be for the best)\n\n# resetting index (when loading a .csv file pandas creates an index automatically, from 0 to Nrecords-1)\ndf.reset_index(drop = True).sort_index().head() # this does not assign the new index though, it just shows you a temp copy\n\n\n#this does assign the new index to your df\ndf = df.reset_index(drop = True).sort_index() \ndf.head()\n\n\n# index isn't unique\ndf.index.is_unique\n\n\n# you can set a new index\n# drop -&gt; Delete columns to be used as the new index.\n# append -&gt;  whether to append columns to existing index.\ndf = df.set_index('eventid', drop=True, append=False)\ndf.index.name = None # remove the index \"name\"\ndf.head()\n\n# this index is not ideal, but it's the original source's id",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-iii-geospatial-vector-data-in-python",
    "href": "labs/w01_intro.html#part-iii-geospatial-vector-data-in-python",
    "title": "1  Introduction & Python Refresher",
    "section": "1.3 Part III: Geospatial Vector data in Python",
    "text": "1.3 Part III: Geospatial Vector data in Python\nGabriele Filomena has prepared this notebook by readapting material shared on this repository. Copyright (c) 2018, Joris Van den Bossche.\n\n%matplotlib inline\n\nimport geopandas as gpd\n\n\n1.3.1 Importing geospatial data\nGeoPandas builds on Pandas types Series and Dataframe, by incorporating information about geographical space.\n\nGeoSeries: a Series object designed to store shapely geometry object\nGeoDataFrame: object is a pandas DataFrame that has a column with geometry (that contains a Geoseries)\n\nWe can use the GeoPandas library to read many of GIS file formats (relying on the fiona library under the hood, which is an interface to GDAL/OGR), using the gpd.read_file function. For example, let’s start by reading a shapefile with all the countries of the world (adapted from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries/, zip file is available in the /data directory), and inspect the data:\n\ncountries = gpd.read_file(\"../data/ne_countries.zip\")\n# or if the archive is unpacked:\n# countries = gpd.read_file(\"../data/ne_countries.shp\")\n\n\ncountries.head()\n\n\ncountries.plot()\n\nWe observe that:\n\nUsing .head() we can see the first rows of the dataset, just like we can do with Pandas.\nThere is a geometry column and the different countries are represented as polygons\nWe can use the .plot() (matplotlib) method to quickly get a basic visualization of the data\n\n\n\n1.3.2 What’s a GeoDataFrame?\nWe used the GeoPandas library to read in the geospatial data, and this returned us a GeoDataFrame:\n\ntype(countries)\n\nA GeoDataFrame contains a tabular, geospatial dataset:\n\nIt has a ‘geometry’ column that holds the geometry information (or features in GeoJSON).\nThe other columns are the attributes (or properties in GeoJSON) that describe each of the geometries.\n\nSuch a GeoDataFrame is just like a pandas DataFrame, but with some additional functionality for working with geospatial data: * A geometry attribute that always returns the column with the geometry information (returning a GeoSeries). The column name itself does not necessarily need to be ‘geometry’, but it will always be accessible as the geometry attribute. * It has some extra methods for working with spatial data (area, distance, buffer, intersection, …) see here, for example.\n\ncountries.geometry.head()\n\n\ntype(countries.geometry)\n\n\ncountries.geometry.area\n\nIt’s still a DataFrame, so we have all the pandas functionality available to use on the geospatial dataset, and to do data manipulations with the attributes and geometry information together. For example, we can calculate the average population over all countries (by accessing the ‘pop_est’ column, and calling the mean method on it):\n\ncountries['pop_est'].mean()\n\n\nafrica = countries[countries['continent'] == 'Africa']\n\n\nafrica.plot();\n\nThe rest of the tutorial is going to assume you already know some pandas basics, but we will try to give hints for that part for those that are not familiar.\n\nImportant: \n\nA GeoDataFrame allows to perform typical tabular data analysis together with spatial operations\nA GeoDataFrame (or Feature Collection) consists of:\n\nGeometries or features: the spatial objects\nAttributes or properties: columns with information about each spatial object\n\n\n\n\n\n1.3.3 Geometries: Points, Linestrings and Polygons\nSpatial vector data can consist of different types, and the 3 fundamental types are:\n\n\nPoint data: represents a single point in space.\nLine data (“LineString”): represented as a sequence of points that form a line.\nPolygon data: represents a filled area.\n\nAnd each of them can also be combined in multi-part geometries (See https://shapely.readthedocs.io/en/stable/manual.html#geometric-objects for extensive overview).\nFor the example we have seen up to now, the individual geometry objects are Polygons:\n\nprint(countries.geometry[2])\n\nLet’s import some other datasets with different types of geometry objects.\nA dateset about cities in the world (adapted from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-populated-places/, zip file is available in the /data directory), consisting of Point data:\n\ncities = gpd.read_file(\"../data/ne_cities.zip\")\n\n\nprint(cities.geometry[0])\n\nAnd a dataset of rivers in the world (from http://www.naturalearthdata.com/downloads/50m-physical-vectors/50m-rivers-lake-centerlines/, zip file is available in the /data directory) where each river is a (Multi-)LineString:\n\nrivers = gpd.read_file(\"../data/ne_rivers.zip\")\n\n\nprint(rivers.geometry[0])\n\n\n\n1.3.4 The shapely library\nThe individual geometry objects are provided by the shapely library\n\nfrom shapely.geometry import Point, Polygon, LineString\n\n\ntype(countries.geometry[0])\n\nTo construct one ourselves:\n\np = Point(0, 0)\n\n\nprint(p)\n\n\npolygon = Polygon([(1, 1), (2,2), (2, 1)])\n\n\npolygon.area\n\n\npolygon.distance(p)\n\n\nImportant: \nSingle geometries are represented by shapely objects:\n\nIf you access a single geometry of a GeoDataFrame, you get a shapely geometry object\nThose objects have similar functionality as geopandas objects (GeoDataFrame/GeoSeries). For example:\n\nsingle_shapely_object.distance(other_point) -&gt; distance between two points\ngeodataframe.distance(other_point) -&gt; distance for each point in the geodataframe to the other point\n\n\n\n\n\n1.3.5 Plotting\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\ncountries.plot(ax = ax, edgecolor='k', facecolor='none')\nrivers.plot(ax=ax)\ncities.plot(ax=ax, color='red')\nax.set(xlim=(-20, 60), ylim=(-40, 40))\n\n\n\n1.3.6 Creating GeoDataFrames (withouth specifying the CRS)\n\ngpd.GeoDataFrame({\n    'geometry': [Point(1, 1), Point(2, 2)],\n    'attribute1': [1, 2],\n    'attribute2': [0.1, 0.2]})\n\n\n# Creating a GeoDataFrame from an existing dataframe\n# For example, if you have lat/lon coordinates in two columns:\ndf = pd.DataFrame(\n    {'City': ['Buenos Aires', 'Brasilia', 'Santiago', 'Bogota', 'Caracas'],\n     'Country': ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Venezuela'],\n     'Latitude': [-34.58, -15.78, -33.45, 4.60, 10.48],\n     'Longitude': [-58.66, -47.91, -70.66, -74.08, -66.86]})\n\n\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\ngdf",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-iv-coordinate-reference-systems-projections",
    "href": "labs/w01_intro.html#part-iv-coordinate-reference-systems-projections",
    "title": "1  Introduction & Python Refresher",
    "section": "2.1 Part IV: Coordinate reference systems & Projections",
    "text": "2.1 Part IV: Coordinate reference systems & Projections\nGabriele Filomena has prepared this notebook by readapting material shared on this repository. Copyright (c) 2018, Joris Van den Bossche.\n\ncountries = gpd.read_file(\"../data/ne_countries.zip\")\ncities = gpd.read_file(\"../data/ne_cities.zip\")\nrivers = gpd.read_file(\"../data/ne_rivers.zip\")\n\n\n2.1.1 Coordinate reference systems\nUp to now, we have used the geometry data with certain coordinates without further wondering what those coordinates mean or how they are expressed.\n\nThe Coordinate Reference System (CRS) relates the coordinates to a specific location on earth.\n\nFor an in-depth explanation, see https://docs.qgis.org/2.8/en/docs/gentle_gis_introduction/coordinate_reference_systems.html\n\n2.1.1.1 Geographic coordinates\n\nDegrees of latitude and longitude.\nE.g. 48°51′N, 2°17′E\n\nThe most known type of coordinates are geographic coordinates: we define a position on the globe in degrees of latitude and longitude, relative to the equator and the prime meridian. With this system, we can easily specify any location on earth. It is used widely, for example in GPS. If you inspect the coordinates of a location in Google Maps, you will also see latitude and longitude.\nAttention!\nin Python we use (lon, lat) and not (lat, lon)\n\nLongitude: [-180, 180]{{1}}\nLatitude: [-90, 90]{{1}}\n\n\n\n\n2.1.2 Projected coordinates\n\n(x, y) coordinates are usually in meters or feet\n\nAlthough the earth is a globe, in practice we usually represent it on a flat surface: think about a physical map, or the figures we have made with Python on our computer screen. Going from the globe to a flat map is what we call a projection.\n\nWe project the surface of the earth onto a 2D plane so we can express locations in cartesian x and y coordinates, on a flat surface. In this plane, we then typically work with a length unit such as meters instead of degrees, which makes the analysis more convenient and effective.\nHowever, there is an important remark: the 3 dimensional earth can never be represented perfectly on a 2 dimensional map, so projections inevitably introduce distortions. To minimize such errors, there are different approaches to project, each with specific advantages and disadvantages.\nSome projection systems will try to preserve the area size of geometries, such as the Albers Equal Area projection. Other projection systems try to preserve angles, such as the Mercator projection, but will see big distortions in the area. Every projection system will always have some distortion of area, angle or distance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjected size vs actual size (Mercator projection): \n\n\n2.1.3 Coordinate Reference Systems in Python / GeoPandas\nA GeoDataFrame or GeoSeries has a .crs attribute which holds (optionally) a description of the coordinate reference system of the geometries:\n\ncountries.crs\n\nFor the countries dataframe, it indicates that it uses the EPSG 4326 / WGS84 lon/lat reference system, which is one of the most used for geographic coordinates.\nIt uses coordinates as latitude and longitude in degrees, as can you be seen from the x/y labels on the plot:\n\ncountries.plot()\n\nThe .crs attribute returns a pyproj.CRS object. To specify a CRS, we typically use some string representation:\n\nEPSG code Example: EPSG:4326 = WGS84 geographic CRS (longitude, latitude)\n\nFor more information, see also http://geopandas.readthedocs.io/en/latest/projections.html.\n\n2.1.3.1 Transforming to another CRS\nWe can convert a GeoDataFrame to another reference system using the to_crs function.\nFor example, let’s convert the countries to the World Mercator projection (http://epsg.io/3395):\n\n# remove Antartica, as the Mercator projection cannot deal with the poles\ncountries = countries[(countries['name'] != \"Antarctica\")]\ncountries_mercator = countries.to_crs(epsg=3395)  # or .to_crs(\"EPSG:3395\")\ncountries_mercator.plot()\n\nNote the different scale of x and y.\n\n\n2.1.3.2 Why using a different CRS?\nThere are sometimes good reasons you want to change the coordinate references system of your dataset, for example:\n\nDifferent sources with different CRS -&gt; need to convert to the same crs.\n\nDifferent countries/geographical areas with different CRS.\nMapping (distortion of shape and distances).\nDistance / area based calculations -&gt; ensure you use an appropriate projected coordinate system expressed in a meaningful unit such as meters or feet (not degrees!).\n\n\nImportant:\nAll the calculations (e.g. distance, spatial operations, etc.) that take place in GeoPandas and Shapely assume that your data is represented in a 2D cartesian plane, and thus the result of those calculations will only be correct if your data is properly projected.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#practice-1",
    "href": "labs/w01_intro.html#practice-1",
    "title": "1  Introduction & Python Refresher",
    "section": "2.2 Practice",
    "text": "2.2 Practice\nAgain, we will go back to the Paris datasets. Up to now, we provided the datasets in an appropriate projected CRS for the exercises. But the original data were actually using geographic coordinates. In the following exercises, we will start from there.\nGoing back to the Paris districts dataset, this is now provided as a GeoJSON file (\"../data/paris_districts.geojson\") in geographic coordinates.\nFor converting the layer to projected coordinates, we will use the standard projected CRS for France is the RGF93 / Lambert-93 reference system, referenced by the EPSG:2154 number.\n\nExercise: Projecting a GeoDataFrame\n\nRead the districts datasets (../data/paris_districts.geojson\") into a GeoDataFrame called districts.\nLook at the CRS attribute of the GeoDataFrame. Do you recognize the EPSG number?\nMake a plot of the districts dataset.\nCalculate the area of all districts.\nConvert the districts to a projected CRS (using the EPSG:2154 for France). Call the new dataset districts_RGF93.\nMake a similar plot of districts_RGF93.\nCalculate the area of all districts again with districts_RGF93 (the result will now be expressed in m²).\n\n\n\nHints\n\n\nThe CRS information is stored in the .crs attribute of a GeoDataFrame.\nMaking a simple plot of a GeoDataFrame can be done with the .plot() method.\nConverting to a different CRS can be done with the .to_crs() method, and the CRS can be specified as an EPSG number using the epsg keyword.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w02_maps.html",
    "href": "labs/w02_maps.html",
    "title": "2  Static Maps in Python",
    "section": "",
    "text": "2.1 Part I: Basic Maps\nIn this session, we will use the libraries matplotlib and contextily to plot the information represented into different GeoDataFrames. We will look into plotting Point, LineString and Polygon GeoDataFrames. Most of the plots here are rather ugly but, at this point, the goal is to get familiar with the parameters of the plot function and what can be done with them.\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport pandas as pd\nimport osmnx as ox\nimport contextily as ctx\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Static Maps in Python</span>"
    ]
  },
  {
    "objectID": "labs/w02_maps.html#part-i-basic-maps",
    "href": "labs/w02_maps.html#part-i-basic-maps",
    "title": "2  Static Maps in Python",
    "section": "",
    "text": "2.1.1 Plotting Points\nLoad the data of terrorist attacks 1970-2020 and choose a country. Germany is used as a case study here but feel free to change the country. If you do so, also change the crs (see https://epsg.io).\n\nattacks = pd.read_csv(\"../data/GTD_2022.csv\", low_memory = False)\n\nCreating the GeoDataFrame from the DataFrame\n\ngermany = ['West Germany (FRG)', 'Germany', 'East Germany (GDR)'] # Germany was split till 1989 in two entities\ndf = attacks[attacks.country_txt.isin(germany)].copy()\n\n# Uncomment the lines below for other countries that haven't changed their denominations/boundaries between 1970 and today:\n# country = 'France' \n# df = attacks[attacks.country_txt == country].copy()#\nwgs = 'EPSG:4326'\ngermany_crs = 'EPSG:4839'\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs = wgs)\ngdf = gdf[~gdf.geometry.is_empty] # remove empty geometries\ngdf.to_file(\"../data/germany.shp\")\ngdf = gdf.to_crs(germany_crs)\n\nC:\\Users\\gfilo\\AppData\\Local\\Temp\\ipykernel_700\\3815068564.py:11: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n  gdf.to_file(\"data/germany.shp\")\n\n\nBasic plotting\n\n# prepare the axis and coordinate\nnr_rows = 1\nnr_cols = 1\nfig, ax = plt.subplots(nr_cols, nr_rows, figsize=(8, 6))\ngdf.plot(ax=ax, color='red', markersize=7)\n\n\n\n\n\n\n\n\nSlightly improving the plot:\n\n# removing ticks\nax.xaxis.set_ticklabels([])\nax.yaxis.set_ticklabels([])\nax.tick_params(axis= 'both', which= 'both', length=0)\ntitle_parameters = {'fontsize':'16', 'fontname':'Times New Roman'}\nax.set_title(\"Terroristic Attacks in Germany\", **title_parameters)\nfig\n\n\n\n\n\n\n\n\n\n2.1.1.1 Adding some context: Base Maps with Contextily\nsee providers and options here https://xyzservices.readthedocs.io/en/stable/introduction.html\n\nsource = ctx.providers.CartoDB.Positron\nctx.add_basemap(ax, crs= gdf.crs.to_string(), source= source)\n# replot\nfig\n\n\n\n\n\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n2.1.1.2 Parameters specific to Point in the plot method\n\nmarkersize: numerical value (for now)\nmarker: see https://matplotlib.org/stable/api/markers_api.html\n\n\n2.1.1.2.1 Other properties, shape independent:\n\ncolor: https://matplotlib.org/3.1.0/gallery/color/named_colors.html\nalpha: regulates transparency of the shape: 0 to 1\n\n\n# first, let's make a function\n\ndef ax_ticks_off(ax):\n    ax.xaxis.set_ticklabels([])\n    ax.yaxis.set_ticklabels([])\n    ax.tick_params(axis= 'both', which= 'both', length=0)\n\n\n# prepare the axis and coordinate\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\ngdf.plot(ax=ax, markersize = 15, color = 'blue', marker = '*', alpha = 0.3)\nctx.add_basemap(ax, crs= gdf.crs.to_string(), source= source)\nax_ticks_off(ax)\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Plotting LineStrings\nLet’s import railway tracks in the Western Balkans (Slovenia, Croatia, Bosnia & Herzegovina, Montenegro, Serbia, Kosovo)\n\nwb_crs = 'EPSG:31277'\nlines_gdf = gpd.read_file(\"..\\data\\wb_railways.shp\")\nlines_gdf.plot()\n\n\n\n\n\n\n\n\n\n# prepare the plot\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nlines_gdf.plot(ax=ax, linewidth = 0.8, color = 'blue', alpha = 1)\nctx.add_basemap(ax, crs= lines_gdf.crs.to_string(), source = ctx.providers.Esri.WorldGrayCanvas)\nax_ticks_off(ax)\nax.set_title(\"Railway infrastructure in the West Balkans\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Railway infrastructure in the West Balkans')\n\n\n\n\n\n\n\n\n\nOne can also filter prior to plotting, based on the columns in the GeoDataFrame. First we download Serbia’s Boundary with OSMNX, more on that later on. Then we filter lines_gdf with a within operation.\n\nserbia = ox.geocode_to_gdf('Serbia')\nserbia = serbia.to_crs(wb_crs)\nserbia_lines = lines_gdf[lines_gdf.geometry.within(serbia.iloc[0].geometry)].copy() #there's only one polygon in the gdf\n\n\n# prepare the plot\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nserbia_lines.plot(ax=ax, linewidth = 0.8, color = 'blue', alpha = 1)\nctx.add_basemap(ax, crs= lines_gdf.crs.to_string(), source = ctx.providers.Esri.WorldGrayCanvas)\nax_ticks_off(ax)\nax.set_title(\"Railway infrastructure in Serbia and Kosovo\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Railway infrastructure in Serbia and Kosovo')\n\n\n\n\n\n\n\n\n\n\n2.1.2.1 Parameters specific to LineString:\n\nlinewidth: numerical value (for now).\ncapstyle: controls how Matplotlib draws the corners where two different line segments meet. See https://matplotlib.org/stable/gallery/lines_bars_and_markers/capstyle.html\njoinstyle’: controls how Matplotlib draws the corners where two different line segments meet. https://matplotlib.org/stable/gallery/lines_bars_and_markers/joinstyle.html\n\n\n# prepare the plot\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nserbia_lines.plot(ax=ax, linewidth = 0.9, color = 'black', alpha = 1, capstyle = 'round', joinstyle = 'round')\nax.set_axis_off() # we don't need the ticks function\nax.set_title(\"Railway infrastructure in Serbia\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Railway infrastructure in Serbia')\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.3 Plotting Polygons\nWe are again using OSMNX to download data from OpenStreetMap automatically. In this case, we will get building footprints from the city of Algiers in Alageria.\n\n2.1.3.1 Parameter specific to Polygon:\n\nedgecolor: the outline of the polygon, by default = None (often better).\nlinewidth: the width of the outline of the polygon.\n\n\nalgeria_crs = 'EPSG:30729'\ntags = {\"building\": True} #OSM tags\nbuildings = ox.features_from_address(\"Algiers, Algeria\", tags = tags, dist = 2000) \nbuildings = buildings.reset_index()\n # sometimes building footprints are represented by Points, let's disregard them\nbuildings = buildings[(buildings.geometry.geom_type == 'Polygon') | (buildings.geometry.geom_type == 'MultiPolygon')]\nbuildings = buildings.to_crs(algeria_crs)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\nax.set_title(\"Buildings in Algiers\", **title_parameters)\nax.set_axis_off() # we don't need the ticks function\nbuildings.plot(ax=ax, color = 'orange', edgecolor = 'black', lw = 0.2)\nsource = ctx.providers.CartoDB.PositronNoLabels\nctx.add_basemap(ax, crs= buildings.crs.to_string(), source= source)\n\n\n\n\n\n\n\n\nFor polygons, you can also plot just the boundaries of the geometries by:\n\nbuildings.boundary.plot(lw = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n2.1.4 Plotting more than one layer together\nLet’s also download roads for Algiers\n\ntags = {\"highway\": True} #OSM tags\nroads = ox.features_from_address(\"Algiers, Algeria\", tags = tags, dist = 2000) \nroads = roads.reset_index()\nroads = roads.to_crs(algeria_crs)\n # sometimes building footprints are represented by Points, let's disregard them\nroads = roads[roads.geometry.geom_type == 'LineString']\n\nAnd plot everything togehter. It’s important to keep in mind that the last layer is always rendered on top of the others. In other words, they may cover the previous ones.\nHowever, you can prevent this by passing arguments to the parameter zorder in the plot method. The layer with the higher zorder value will be plotted on top.\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\nax.set_title(\"Buildings and Roads in Algiers\", **title_parameters)\nax.set_axis_off() # we don't need the ticks function\n# only roads within the extent of the buildings layer\nroads[roads.geometry.within(buildings.unary_union.envelope)].plot(ax=ax, color = 'grey', lw = 0.5) #linewidth can be also passed as lw \nbuildings.plot(ax=ax, color = 'orange')\n\n\n\n\n\n\n\n\n\n\n2.1.5 Sub-plots\nTo obtain multiple sub-plots, we manipulate the nrows, ncols parameters. We can use this approach to: * Plot the same layer with different properties.\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\ncolors = ['red', 'blue']\n\nfor n, ax in enumerate(axes):\n    gdf.plot(ax=ax, markersize = 4, color = colors[n])\n    ax.set_axis_off()\n    ctx.add_basemap(ax, crs= gdf.crs.to_string(), source= source)\n\n\n\n\n\n\n\n\n\nPlot different layers.\n\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\ngdfs = [buildings, roads]\ncolors = ['orange', 'grey']\n\nbuildings.plot(ax=axes[0], color = 'orange', edgecolor = 'none')\nroads.plot(ax=axes[1], color = 'gray', lw = 0.5)\n\nfor ax in axes:\n    ax.set_axis_off()\n    ctx.add_basemap(ax, crs= buildings.crs.to_string(), source = source)\n\n\n\n\n\n\n\n\n\nAnalyse phenomena across different geographical areas. For example, terrorism in Germany and in the UK.\n\n\n# let's prepare the gdf for the UK\ndf_uk = attacks[attacks.country_txt == 'United Kingdom'].copy()\nuk_crs = 'EPSG:27700'\ngdf_uk = gpd.GeoDataFrame(df_uk, geometry=gpd.points_from_xy(df_uk.longitude, df_uk.latitude), crs = wgs)\ngdf_uk = gdf_uk.to_crs(uk_crs)\n\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\ngdfs = [gdf, gdf_uk]\n\nfor n, ax in enumerate(axes):\n    gdf_tmp = gdfs[n]\n    gdf_tmp.plot(ax=ax, color = 'orange', markersize = 3)\n    ax.set_axis_off()\n    ctx.add_basemap(ax, crs= gdf_tmp.crs.to_string(), source= source)\n\n\n\n\n\n\n\n\n\nExercise:\n\nThink about the plots above and how they could be improved.\nCopy and paste the code and execute the functions playing with the different parameters.\nProduce a neat map using the GeoDataFrames available in this notebook or the ones employed in the previous sessions, making use of the elements/parameters discussed here.\nTry out different tiles for the basemap to familiarise yourself with what’s available.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Static Maps in Python</span>"
    ]
  },
  {
    "objectID": "labs/w02_maps.html#part-ii-choropleth-mapping",
    "href": "labs/w02_maps.html#part-ii-choropleth-mapping",
    "title": "2  Static Maps in Python",
    "section": "2.2 Part II: Choropleth Mapping",
    "text": "2.2 Part II: Choropleth Mapping\n\nimport geoplot.crs as gcrs\nimport geoplot as gplt\n\nData\nFor this second part of the tutorial, we will use some data at the municipality level for Serbia. The data contains information regarding poverty level, average income, population and tourism. The data is taken from https://data.stat.gov.rs/?caller=SDDB&languageCode=en-US and can be associated to the polygons representing the administrative boundaries of the municipalities. These boundaries can be found here https://data.humdata.org/dataset/geoboundaries-admin-boundaries-for-serbia?force_layout=desktop. While most of the data refers to 2023, the admin boundaries file traces back to 2017. Thus, it may contain obsolete information (few changes may occur).\nLater on, we will go back to the terrorism dataset.\n\n# This will be different on your computer and will depend on where\n# you have downloaded the files\nserbia_crs = 'EPSG:31277'\nwgs = 'EPSG:4326'\nserbia_admin = gpd.read_file('../data/serbia_admin.shp')\nserbia_admin.set_index('townID', inplace = True, drop = True)\nserbia_admin = serbia_admin.to_crs(serbia_crs)\n\nLet’s plot the GeoDataFrame following the last session’s steps.\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nserbia_admin.plot(ax = ax, color = 'salmon', linewidth = 0.3, edgecolor = 'white')\nax.set_axis_off()\ntitle_parameters = {'fontsize':'16', 'fontname':'Times New Roman'}\nax.set_title(\"Serbian Municipalities\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Serbian Municipalities')\n\n\n\n\n\n\n\n\n\nThe we load the data and merge it into the GeoDataFrame, before getting rid of municipalities that do not have a corresponding shape/record in the GeoDataFrame (probably the result of changes in the national subdivisions).\n\ndata = pd.read_csv(\"../data/serbia_data.csv\") #some slavic characters \ndata.drop('name_en', axis = 1, inplace = True)\nserbia_admin = pd.merge(serbia_admin, data, left_on = \"townID\", right_on = \"id\")\nserbia_admin = serbia_admin[serbia_admin.id.notna()]\nserbia_admin['id'] = serbia_admin['id'].astype('int64')\nserbia_admin.head()\n\n#let's save the so-obtained gdf for later (encoding for dealing with slavic characters).\nserbia_admin.to_file(\"../data/serbia_data.shp\", encoding='utf-8')\n\nCreating a choropleth map is rather straightforward and can ben done by using few other parameters. Reflect on what you see and whether the map below is informative.\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nserbia_admin.plot(ax = ax, column = 'gross', linewidth = 0.3, cmap = 'Greens', legend = True)\nax.set_axis_off()\ntitle_parameters = {'fontsize':'16', 'fontname':'Times New Roman'}\nax.set_title(\"Serbian Municipalities\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Serbian Municipalities')\n\n\n\n\n\n\n\n\n\n\n2.2.1 Choropleth Maps for Numerical Variables\nWe are essentially using the same approach employed for creating basic maps, the method plot, but we now need to pass arguments to some new parameters to specify which column is to be represented and how. As an optional argument, one can set legend to True and the resulting figure will include a colour bar.\n\ncolumn: the name of the column representing the variable that we want to use to colour-code our shapes.\nscheme: the scheme used to colour the shapes based on the variable values.\ncmap: the colormap used to show variation.\n\n\n2.2.1.1 Colormaps\nBuilt-in colour maps can be found here https://matplotlib.org/stable/gallery/color/colormap_reference.html. However one can create new ones as follows from a list of colours:\n\nfrom seaborn import palplot\nfrom matplotlib.colors import LinearSegmentedColormap\n\ncolors = [(0.00, 0.00, 0.00,1), (0.248, 0.0271, 0.569, 1), (0.0311, 0.258, 0.646,1),\n            (0.019, 0.415, 0.415,1), (0.025, 0.538, 0.269,1), (0.0315, 0.658, 0.103,1),\n            (0.331, 0.761, 0.036,1),(0.768, 0.809, 0.039,1), (0.989, 0.862, 0.772,1),\n            (1.0, 1.0, 1.0)]\npalplot(colors)\n\n\n\n\n\n\n\n\n\nkindlmann = LinearSegmentedColormap.from_list('kindlmann', colors)\n\nor from colour names:\n\ncolors = [\"white\", \"yellow\", \"red\"]\npalplot(colors)\n\n\n\n\n\n\n\n\nLet’s try a new colormap and let’s also set a number of classes to divide the data in, through the parameter k.\n\nwhite_to_red = LinearSegmentedColormap.from_list(\"name\", [\"yellow\",\"red\"])\n\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nserbia_admin.plot(ax = ax, column = 'gross', linewidth = 0.3, cmap = kindlmann.reversed(), legend = True, k = 8)\nax.set_axis_off()\ntitle_parameters = {'fontsize':'16', 'fontname':'Times New Roman'}\nax.set_title(\"Serbian Municipalities\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Serbian Municipalities')\n\n\n\n\n\n\n\n\n\nWith GeoPandas, when you use the plot method with legend=True the type of legend that appears depends on the data being visualized:\n\nContinuous Data: For columns with continuous data (like population estimates, temperatures, etc.), a colour bar is generated as the legend. This color bar represents a range of values with a gradient, indicating how data values correspond to colours on the map.\nCategorical Data: For columns with categorical data (like country names, types of land use, etc.), if you specify legend=True, GeoPandas will try to create a legend that categorizes these distinct values with different colours. However, creating legends for categorical data is not as straightforward as with continuous data and might require additional handling for a clear and informative legend (see below).\n\n\n\n2.2.1.2 Scheme\nIt is important to keep in mind that choropleth maps strongly depend on the scheme that it is passed (or the default one) to classify the data in groups. The plot above only shows one municipality coloured in dark blue.\nLook at the following plots and how three different classifiers produce different results for the same data.\nRefer to https://geopandas.org/en/stable/gallery/choropleths.html and https://geographicdata.science/book/notebooks/05_choropleth.html for further details\n\n# Function for plotting the map and the distribution of the value in bins  \n\nfrom mapclassify import Quantiles, EqualInterval, FisherJenks\n\ndef plot_scheme(gdf, column, scheme, figsize=(10, 6)):\n    '''\n    Arguments\n    ---------\n    gdf: GeoDataFrame\n        The GeoDataFrame to plot\n    column: str\n        Variable name \n    scheme: str\n        Name of the classification scheme to use \n    figsize: Tuple\n        [Optional. Default = (10, 6)] Size of the figure to be created.\n\n    '''\n    schemes = {'equal_interval': EqualInterval, 'quantiles': Quantiles, 'fisher_jenks': FisherJenks} \n    classification = schemes[scheme](gdf[column], k=7)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n    # KDE\n    sns.kdeplot(gdf[column], fill=True, color='purple', ax=ax1)\n    sns.rugplot(gdf[column], alpha=0.5, color='purple', ax=ax1)\n    for cut in classification.bins:\n        ax1.axvline(cut, color='blue', linewidth=0.75)\n    ax1.set_title('Value distribution')\n    # Map\n    p = gdf.plot(column=column, scheme=scheme, alpha=0.75, k=7, cmap='RdPu', ax=ax2, linewidth=0.1)\n    ax2.axis('equal')\n    ax2.set_axis_off()\n    ax2.set_title('Geographical distribution')\n    fig.suptitle(scheme, size=25)\n    plt.show()\n\n\nThe Equal intervals method splits the range of the distribution, the difference between the minimum and maximum value, into equally large segments and to assign a different colour to each of them according to a palette that reflects the fact that values are ordered.\nTo obtain a more balanced classification, one can use the Quantiles scheme. This assigns the same amount of values to each bin: the entire series is laid out in order and break points are assigned in a way that leaves exactly the same amount of observations between each of them. This “observation-based” approach contrasts with the “value-based” method of equal intervals and, although it can obscure the magnitude of extreme values, it can be more informative in cases with skewed distributions.\nAmongst many other, the Fisher Jenks dynamically minimises the sum of the absolute deviations around class medians. The Fisher-Jenks algorithm is guaranteed to produce an optimal classification for a prespecified number of classes.\n\nThe only additional arguments to pass for producing a choropleth, therefore, are the actual variable we would like to classify and the number of segments we want to create, k. This is, in other words, the number of colours that will be plotted on the map so, although having several can give more detail, at some point the marginal value of an additional one is fairly limited, given the ability of the human brain to tell any differences.\n\nschemes = ['equal_interval', 'quantiles', 'fisher_jenks']\nfor scheme in schemes:\n    plot_scheme(serbia_admin, 'gross', scheme)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlso consider the Modifiable Areal Unit Problem and how the geographies of the administrative boundaries, in this case, may impact the visualisation.\n\nFor example, the most populated area is a municipality in the north that corresponds to the city of Novi Sad. Let’s have a look at the data\n\nserbia_admin[['name', 'pop', 'Province']].sort_values(by = 'pop', ascending = False).iloc[:10]\n\n\n\n\n\n\n\n\nname\npop\nProvince\n\n\n\n\n48\nNovi Sad\n341625.0\nJužno-Bački\n\n\n24\nNovi Beograd\n186667.0\nGrad Beograd\n\n\n19\nČukarica\n154854.0\nGrad Beograd\n\n\n3\nKragujevac\n154290.0\nŠumadijski\n\n\n26\nPalilula\n148292.0\nGrad Beograd\n\n\n34\nZemun\n143173.0\nGrad Beograd\n\n\n32\nVoždovac\n137315.0\nGrad Beograd\n\n\n35\nZvezdara\n130225.0\nGrad Beograd\n\n\n39\nLeskovac\n123201.0\nJablanički\n\n\n120\nSubotica\n121250.0\nSeverno-Bački\n\n\n\n\n\n\n\nIn our dataset, the city of Novi Sad is categorised as a municipality by itself, because the administrative boundaries file is not updated. In reality, “since 2002, when the new statute of the city of Novi Sad came into effect, Novi Sad is divided into two city municipalities, Petrovaradin and Novi Sad. From 1989 until 2002, the name Municipality of Novi Sad meant the whole territory of the present-day city of Novi Sad.” (see: wikipedia).\nOn the contrary, Grad Beograd, that is Belgrade, is correctly split into different municipalities and its population, when visualised, is spread out across the different geometries of its municipalities. In other words, our map depends on the geometries of the areas and on how the data was collected. While it could be that these areas were indeed identified by population size in the first place, the point is that the fact that Novi Sad is not split into more areas, as Belgrade is, makes it stound out more clearly from the map (and to some extent a bit unfairly)\nThis may happen with different types of data, particularly with administrative boundaries and it is crucial to reflect on how Choropleth maps may be impacted. One can look for more granular data or consider to weight the continuous value with the extent of the area (i.e. obtaining density values).\n\n\n2.2.1.3 An alternative to scheme: ColorMap Normalisation\nThe mpl.colors.Normalize function in matplotlib creates a normalization object, which adjusts data values into a range that is ideal for colour mapping in a colormap. This function is particularly beneficial in scenarios where precise control over the mapping of data values to colour representations is needed.\nWhen employed in a plotting function, this normalization object ensures that the data values are scaled to fit a pre-defined range (for instance, norm = mpl.colors.Normalize(vmin=0, vmax=40)). Any values falling below 0 are mapped to the lowest colour on the colormap scale, while values exceeding 40 are mapped to the highest colour. This approach is especially useful when aiming to highlight differences within a specific data range; it can significantly enhance the visualization of data, by, for example, emphasizing temperature variations between 0°C and 40°C. This becomes crucial in instances where a few data points with high values (e.g., 50°C) might otherwise lead to a less informative visualization if not ‘normalized’ and treated as if they corresponded to 40° C values.\nFor our dataset, we can use as vmax the value corresponding to the 90th percentile.\n\nserbia_admin['pop'].quantile(0.90)\n\n93014.0\n\n\n\nimport matplotlib as mpl\nfig, ax = plt.subplots(1, 1)\nvmin = serbia_admin['pop'].min()\nvmax = serbia_admin['pop'].quantile(0.90) # \nnorm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\nserbia_admin.plot(ax = ax, column='pop', cmap='OrRd', legend=True, norm = norm)\n\n\n\n\n\n\n\n\n\nImportant: \nWhen passing norm in the plot method, do not pass the arguments to the scheme parameter. For continuous variables, norm maps each value directly to a color, making discrete categorization redundant. In other words, it allows for a direct mapping of data values to the color map, eliminating the need for intermediary classification schemes. norm ensures a smooth gradient in the color map without artificially segmenting the data.\n\n\n\n2.2.1.4 Customising the colorbar\n\nimport matplotlib.cm as cm\n\nfig, ax = plt.subplots(1, 1)\ncmap = 'YlOrRd'\n# we leave the legend out\nserbia_admin.plot(column='pop', cmap=cmap, norm = norm, ax=ax)\n\n# we add the colorbar separately passing the norm and cmap\ncbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax = ax)\ncbar.outline.set_visible(False)\n\n# updating ticks VALUES\nticks = [norm.vmin, norm.vmax]\ncbar.set_ticks(ticks = ticks)\n\n# updating ticks LABELS\ncbar.ax.set_yticklabels([round(t,1) for t in ticks])\ncbar.ax.set_yticklabels([round(t,1) if t &lt; norm.vmax else \"&gt;= \"+str(round(t,1)) for t in cbar.ax.get_yticks()])\n\n\n\n\n\n\n\n\nAbove, we removed the outline of the color bar. Then we set the tick values to the min and the max population values, based on our norm object. Then, for the vmax value’s label we added a “&gt;=” to remind us that other, higher values are displayed with the darkest color.\n\n\n2.2.1.5 Varying alpha transparency based on an array\nFinally, we can also convey variation in a continuous scale through transparency. alpha doesn’t expect column names, so we cannot just pass the name of the column containing the variable. Instead, we have to create an array from 0.0 to 1.0 values. To so we can a) use normalisation methods, or b) rescale the original values within 0 to 1 based on the original min and max values.\nFor example, with square root normalization:\n\n# 1. Create an alpha array based on a normalized value (e.g., population)\nimport numpy as np\npop_max = serbia_admin['pop'].max()\nalpha = np.sqrt(serbia_admin['pop'] / pop_max) \n\n\n# Plot with varying alpha values\nfig, axes = plt.subplots(1, 2, figsize=(10, 6))\nserbia_admin.plot(color = 'blue', ax=axes[0], alpha=alpha, edgecolor='black', linewidth = 0.3) #one color\nserbia_admin.plot(cmap = 'YlOrRd', ax=axes[1], alpha=alpha, edgecolor='red', linewidth = 0.3) #cmap\nfor ax in axes:\n    ax.set_axis_off()\n\n\n\n\n\n\n\n\n\nImportant: \nmatplotlib would not able to plot a color bar from variations in the alpha value since no column is passed directly. We would need, in this case, to build a color bar manually as demonstrated above.\n\n\n\n\n2.2.2 Choropleth Maps for Categorical Variables\nA choropleth for categorical variables assigns a different color to every potential value in the series based on certain colormaps (cmap). We don’t need to specify a scheme in this case, but just to the categorical column. Using last’s week GeoDataFrame, we can plot terrorist attacks in Germany, for example, by group.\n\ngdf = gpd.read_file(\"../data/germany.shp\").to_crs(germany_crs)\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\ngdf.plot(ax = ax, column = 'gname', legend = True)\nax.set_axis_off()\ntitle_parameters = {'fontsize':'16', 'fontname':'Times New Roman'}\nax.set_title(\"Terrorist Attacks in Germany, by Group\", **title_parameters) #parameters as above\n\nText(0.5, 1.0, 'Terrorist Attacks in Germany, by Group')\n\n\n\n\n\n\n\n\n\nThe map above is what you would get from datasets that are not cleaned/manipulated directly or when there are too many categories in the selected column. First, let’s get a slimmer slice of the gdf that only contains attacks that cause a number of fatalities and wounded higher than 10.\n\ncondition = (gdf.nkill + gdf.nwound) &gt; 10\ngdf_filtered = gdf[condition].copy()\n\nThen, let’s build a function that creates a random color map based on the number of categories. This creates random HUE-based colors:\n\n# Generate random colormap\ndef rand_cmap(nlabels):\n    \"\"\" \n    It generates a categorical random color map, given the number of classes\n    \n    Parameters\n    ----------\n    nlabels: int\n        The number of categories to be coloured.\n    type_color: str {\"soft\", \"bright\"} \n        It defines whether using bright or soft pastel colors, by limiting the RGB spectrum.\n       \n    Returns\n    -------\n    cmap: matplotlib.colors.LinearSegmentedColormap\n        The color map.\n    \"\"\"   \n    # Generate color map for bright colors, based on hsv\n    randHSVcolors = [(np.random.uniform(low=0.20, high=0.80),\n                          np.random.uniform(low=0.20, high=0.80),\n                          np.random.uniform(low=0.20, high= 0.80)) for i in range(nlabels)]\n\n    random_colormap = LinearSegmentedColormap.from_list('new_map', randHSVcolors, N=nlabels)\n   \n    return random_colormap \n\n\ncmap = rand_cmap(len(gdf_filtered.gname.unique()))\ncmap\n\nnew_map  underbad over \n\n\nWe also place the legend on the centre left. This is done automatically, but the legend and its items can be manipulated directly. Legends in matplotlib are extremely complex to personalise. However, do have a look at https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html#matplotlib.pyplot.legend for both automatic and explicit manipulation.\n\nlegend_kwds={\"loc\": \"center left\", \"bbox_to_anchor\": (1, 0.5)}\n\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\ngdf_filtered.plot(ax = ax, column = 'gname', legend = True, cmap = cmap, legend_kwds = legend_kwds)\ntitle_parameters = {'fontsize':'16', 'fontname':'Times New Roman'}\nax.set_title(\"Terrorist Attacks in Germany, by Group\", **title_parameters) #parameters as above\nctx.add_basemap(ax, crs= gdf_filtered.crs.to_string(), source = ctx.providers.Esri.WorldGrayCanvas)\n\n\n\n\n\n\n\n\nWe can also convey the impact of the events through the markersize. This introduces the concept of cartogram (see below).\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\ngdf_filtered.plot(ax = ax, column = 'gname', markersize = 'nwound', legend = True, cmap = cmap, legend_kwds = legend_kwds)\nax.set_title(\"Terrorist Attacks in Germany, by Group\", **title_parameters) #parameters as above\nctx.add_basemap(ax, crs= gdf_filtered.crs.to_string(), source = ctx.providers.Esri.WorldGrayCanvas)\nax.set_axis_off()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Static Maps in Python</span>"
    ]
  },
  {
    "objectID": "labs/w02_maps.html#part-iii-cartograms---manipulating-the-geometry-size-for-showing-the-magnitude-of-a-value",
    "href": "labs/w02_maps.html#part-iii-cartograms---manipulating-the-geometry-size-for-showing-the-magnitude-of-a-value",
    "title": "2  Static Maps in Python",
    "section": "2.3 Part III: Cartograms - Manipulating the Geometry size for showing the magnitude of a value",
    "text": "2.3 Part III: Cartograms - Manipulating the Geometry size for showing the magnitude of a value\nCartograms are maps that represent the spatial distribution of a variable not by encoding it in a color palette but rather by modifying geographical objects. There are many algorithms to distort the shapes of geographical entities according to values, some of them are rather complex.\n\n2.3.1 Polygons\nYou can obtain cartograms for Polygon with geoplot: see https://residentmario.github.io/geoplot/\ngeoplot functions pretty much work as plot\n\n# this library needs the GeoDataFrame to be reverted to WGS\nax = gplt.cartogram(serbia_admin.to_crs(wgs), scale='pop', projection=gcrs.Mercator(), color = 'darkblue')\n# see for projections that work with gplt https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html\ngplt.polyplot(serbia_admin.to_crs(wgs), facecolor='lightgray', edgecolor='white', ax=ax, lw = 0.5) # this is just for comparison\n\n\n\n\n\n\n\n\n\n\n2.3.2 Points\nFor Point GeoDataFrames we can just go back to plot and pass a column name to markersize.\n\nattacks = pd.read_csv(\"../data/GTD_2022.csv\", low_memory = False)\ncountry = 'Germany'\n\ndf = attacks[attacks.country_txt == country].copy()\nwgs = 'EPSG:4326'\ngermany_crs = 'EPSG:4839'\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs = wgs)\ngdf = gdf.to_crs(germany_crs)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\ngdf.plot(ax = ax, markersize = 'nwound', color = 'purple', legend = True)\nax.set_axis_off()\n\n\n\n\n\n\n\n\nOne can also convert polygons into points by using their centroids, and then define the size of the dot proportionally to the value of the variable we want to display.\n\n\n2.3.3 LineString\nFor LineString we pass the column name to linewidth.\nLet’s load a shapefile of lines. These lines represent frequency of train connections from/to train stations in the region of Liguria (Italy) to other stations within or outside the region. Each line refers to a connection between two specific stations, through a certain type of service and contains information about the frequency of that type of service. For example, the cities of Savona and Finale Ligure might be connected by 5 InterCity trains and 50 regional services. These services correspond to 2 different records.\n\ntrains_freq = gpd.read_file(\"../data/trains_liguria.shp\" )\ntrains_freq.crs\n\n&lt;Projected CRS: EPSG:3003&gt;\nName: Monte Mario / Italy zone 1\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: Italy - onshore and offshore - west of 12°E.\n- bounds: (5.93, 36.53, 12.0, 47.04)\nCoordinate Operation:\n- name: Italy zone 1\n- method: Transverse Mercator\nDatum: Monte Mario\n- Ellipsoid: International 1924\n- Prime Meridian: Greenwich\n\n\nLet’s check the type of services contained here.\n\ntrains_freq['train_type'].unique()\n\narray(['REG', 'IC', 'FB', 'ICN', 'U', 'EC/EN', 'AV'], dtype=object)\n\n\nWe have: - ‘REG’: regional trains. - ‘IC’: intercity trains. - ‘FB’: similar to IC, but slightly faster. - ‘ICN’: sleeper trains. - ‘U’: urban trains (Genoa). - ‘EC/EN’: international trains. - ‘AV’: High-speed trains.\nLet’s keep just regional, intercity, and high-speed trains.\n\nto_keep = ['REG', 'IC', 'AV']\ntrains_freq = trains_freq[trains_freq['train_type'].isin(to_keep)]\n\nThe usage of linewdith is a bit different from markersize for some reason. We have to pass an array of N values, where N is equal to the GeoDataFrame size. In other words, we have to pass the column we want to use to regulate the line width directly as a list/array. Specifying the column name is not enough.\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 15))\ntrains_freq.plot(ax = ax, linewidth = trains_freq['freq'])\nax.set_axis_off()\n\n\n\n\n\n\n\n\nAs you can see, the default arguments and simply passing the column values do not produce pretty results. The first thing to look at is the values that are passed to linewidth. In some cases, the min and max values, as well as their distribution, are not ideal for visually conveying the magnitude of the variable attached to the geometry. One option is to use a multiplier factor (see below), or to rescale the values from 0 to 1, for example, and then, again, if necessary use a multiplier.\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 20))\nlw = trains_freq['freq'] * 0.15\ntrains_freq.plot(ax = ax, linewidth = lw, capstyle = 'round', joinstyle = 'round', column = 'train_type', legend = True)\nctx.add_basemap(ax, crs= trains_freq.crs.to_string(), source = ctx.providers.Esri.WorldGrayCanvas)\nax.set_axis_off()\n\n\n\n\n\n\n\n\nWhile this looks a bit better, this visualisation is not ideal because the frequencies are not snapped to the actual railway network. The lines represent, instead, connection between train stops and therefore their coordinates only include the ones corresponding to the stations where the different services call at. One can devise approaches to:\n\nAssigning the frequencies, or any other value, to the corresponding infrastructure’s section. For example, the railway section between two stations could be associated with a value representing the total number of regional/local services travelling along it.\nSmoothing the lines representing the services by adding further coordinates along the line.\n\nBoth these processes go beyond the scopes of this lab and require several considerations depending on the data, the scale, and what information one wants to displays.\n\nExercise:\nToday we’ve seen how to exploit matplotlib to plot GeoDataFrame layers. Go through the notebook again if you feel that there’s something you need to review. You are not expected to remember each step/method/parameter. Rather, this notebook should be used as a reference for producing maps in Python. Do keep in mind that most of the maps above have been produced with just a bunch of rows, so each of them can be improved and embellished with some more effort.\nNow, if you are not overwhelmed, have a look at the very last map and produce some nice visualisation using the same data. You can further improve its clarity, add a legend that refers to the line width, visualise only a certain type of services, or add information/context, for example. In the folder \\data you can also find a .shp file containing all the train stations in Italy, should you need that.\n\n\n2.3.3.1 Saving figures (check here for details)\n\nfig.savefig(\"fig1.pdf\", dpi='figure', format=\"pdf\", bbox_inches = 'tight')",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Static Maps in Python</span>"
    ]
  }
]